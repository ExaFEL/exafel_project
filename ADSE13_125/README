Scripts for running IOTA demo on Cori KNL

Initial scripts courtesy Mona <monarin@stanford.edu>.
Contact: Asmit Bhowmick <abhowmick@lbl.gov>
         Nick Sauter <nksauter@lbl.gov>


##### STEPS TO FOLLOW FOR IOTA DEMO ########

1. Please use the Dockerfile in docker_psana2 in the exafel_project repository to build your own docker/shifter image. 
   If you wish to use the one for the demo on Cori-PII, it is registry.services.nersc.gov/asmit/iota_ps2_v2:latest 

2. Copy over this folder to a location where you wish to process data. That location is your BASE_PATH in the submit
   scripts provided here.

3. Next decide which filesystem you would like to read in data from and read out data to. If anything involves burst
   buffer, use the processing/burst_buffer scripts. Otherwise use the scripts in processing/lustre_fs. Please do not 
   try this demo on the GPFS system. Read the instructions very carefully in the submission script as well as the 
   associated script that is run by that submission script (see point 4)

4. Following are the 4 types of cases for which submission scripts have been provided

   Submission script               |       script that is run       |  Indexing algorithm  |    Location

 a)  sbatch.sh 				docker_xtc_process.sh   	Conventional	     processing/lustre_fs
 b)  sbatch_iota.sh (used for DEMO)     docker_xtc_process_iota.sh      IOTA		     processing/lustre_fs
 c)  sbatch_bb.sh                       docker_xtc_process_bb.sh        Conventional         processing/burst_buffer
 d)  sbatch_iota_bb.sh                  docker_xtc_process_iota_bb.sh   IOTA                 processing/burst_buffer


5. The IOTA/Conventional indexing codes that were used for the project have been provided in processing/command_line. The xtc_process.py script is from cctbx_project/xfel/command_line. The xtc_process_iota_srs.py script is from exafel_project/ADSE13_25/command_line. The scripts provided here represent the state they were at the time of the demo.


5. You will have to change the DATA_DIR variable in the docker_xtc_process_**.sh script which you choose to use.
   This DATA_DIR points to where the xtc2 streams are.


6. Submit the submission scripts using the sbatch command to the Cori queue.
   Example is in processing/lustre_fs ==> sbatch sbatch_iota.sh


7. Once the job is over, you will have to run the indexing analytics package to figure out performance metrics
   We used a Standard Reporting format for this project that allows us to report timings as well as scientific
   performance and compare it across different situations. To generate the relevant table, please run the script
   processing/lustre_fs/sbatch_idx_analytics.sh. This can be run for jobs run on the burst buffer as well after data has   been staged out completely. Things to change in that script
     o change the sources via the variable CCTBX_XFEL
     o wall_time ==> time in seconds it took for the processing job in (6) to finish 
     o num_nodes ==> Number of nodes used for running the job in (6)

8. Merging step --> TO BE UPDATED. Please look at merging/
